<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta property="og:title" content="BiPO: Bidirectional Partial Occlusion Network for Text-to-Motion Synthesis"/>
  <meta property="og:url" content="https://seoneun.github.io/BiPO-page/"/>
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <title>BiPO: Bidirectional Partial Occlusion Network for Text-to-Motion Synthesis</title>
  <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-EWRYSDM25P"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-EWRYSDM25P');
</script>
  
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">
  <link rel="icon" href="static/figures/icon2.png">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>


<section class="publication-header">
  <div class="hero-body">
    <div class="container is-max-widescreen">
      <div class="column has-text-centered">
        <h1 class="title is-1 publication-title">BiPO: Bidirectional Partial Occlusion Network for Text-to-Motion Synthesis</h1>
        <div class="is-size-3 publication-authors">
          Arxiv 2024
        </div>
      </div>
    </div>
  </div>
</section>

<section class="publication-author-block">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="" target="_blank">Seong-Eun Hong</a>,</span>
            <span class="author-block"><a href="" target="_blank">Soobin Lim</a>,</span>
            <span class="author-block"><a href="" target="_blank">Juyeong Hwang</a>,</span>
            <span class="author-block"><a href="" target="_blank">Minwook Chang</a>,</span>
            <span class="author-block"><a href="" target="_blank">Hyeongyeop Kang</a></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Korea University, NC Research, NCSOFT Corp.</span> 
          </div>
          
          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/abs/2412.00112" target="_blank"
                  class="external-link button is-normal is-rounded">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2412.00112" target="_blank"
                  class="external-link button is-normal is-rounded">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/seoneun/BiPO" target="_blank"
                class="external-link button is-normal is-rounded">
                <span class="icon">
                  <i class="fab fa-github"></i>
                </span>
                <span>Code</span>
              </a>
              </span>

              <span class="link-block">
                <a href="." target="_blank"
                class="external-link button is-normal is-rounded">
                <span class="icon">
                  <i class="fas fa-rocket"></i>
                </span>
                <span>Demo</span>
              </a>
              </span>

            </div>
          </div>

        </div>
      </div>
    </div>
  </div>
</section>


<section class="section hero is-light">
  <div class="container" style="text-align:center;">
    <video style="width:720px; height:auto; display:block; margin:auto;" controls>
      <source src="static/figures/BiPo.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
    <h2 class="title is-3" style="margin-top:30px;">Abstract</h2>
    <div class="content" style="text-align:justify; width:720px; margin:auto;">
      <p>
        Text-to-motion generation has considerably advanced with part-based autoregressive models. Traditional unidirectional approaches are limited by their inability to access future tokens, leading to constrained temporal coherence and suboptimal motion quality. Furthermore, autoregressive models are challenging to apply to motion editing tasks. Recently, bidirectional autoregressive models have been proposed, integrating past and future contexts to enhance consistency. In this work, we introduce the first model to combine part-based generation with bidirectional autoregressive methods. This approach leverages detailed control over individual parts alongside rich temporal context, with the added advantage of applicability to motion editing tasks. However, it can cause parts to rely too heavily on each other, as each part must account for expanded contextual information. This reliance can result in tangled motion sequences and compounding small errors in both directions along the sequence. To resolve these issues, we propose Partial Occlusion, a stochastic training technique that probabilistically occludes specific motion part information, encouraging the model to learn robust representations under partial context. We combine these contributions into BiPO. Our model achieves superior performance in FID on HumanML3D compared to previous part-based methods and sets a new state-of-the-art.
      </p>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container" style="text-align:center;">
      <h2 class="title is-3">BiPO's Architecture</h2>
      <img src="static/figures/Figure2.png" alt="BiPO Architecture Diagram" style="width:720px; height:auto; display:block; margin:auto;"/>
      <div class="content" style="text-align:justify; width:720px; margin:auto;">
      <p>BiPO introduces a novel part-based bidirectional autoregressive network designed to generate coherent and controllable human motions from textual descriptions. Unlike existing approaches that either rely solely on unidirectional generation or lack per-part controllability, BiPO represents the human body as multiple parts—root, backbone, arms, and legs—each generated through its own transformer-based pipeline. These parts can reference one another through a Selective Part Coordination Layer, enabling the model to maintain global motion coherence while allowing fine-grained control at the part level. To prevent parts from becoming overly reliant on one another, BiPO employs Partial Occlusion, randomly obscuring certain part tokens during training. This encourages each component to learn robust representations independently, resulting in more stable and natural full-body motion synthesis.</p>
      </div>
      </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container" style="text-align:center;">
    <h2 class="title is-3">Inference</h2>
    <img src="static/figures/Figure3.png" alt="BiPO Architecture Diagram" style="width:720px; height:auto; display:block; margin:auto;"/>
    <div class="content" style="text-align:justify; width:720px; margin:auto;">
    <p>During inference, BiPO employs a dual-phase decoding strategy to refine the motion output. In the initial phase, each body part’s motion tokens are generated in a unidirectional manner, guided by the textual prompt. This step provides a coarse yet contextually appropriate sequence. In the second phase, BiPO applies a bidirectional autoregressive refinement: selectively masking and regenerating certain tokens while considering both past and future context. By integrating the updated tokens from all parts, the model corrects potential inconsistencies and enhances the temporal smoothness and structural integrity of the motion. The result is a polished, high-quality motion sequence that faithfully represents the provided text.</p>
    </div>  
    </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container" style="text-align:center;">
      <h2 class="title is-3">Qualitative test</h2>  
      <img src="static/figures/Figure4.PNG" alt="BiPO Architecture Diagram" style="width:720px; height:auto; display:block; margin:auto; margin-bottom:30px;"/>
      <img src="static/figures/Figure5.PNG" alt="BiPO Architecture Diagram" style="width:720px; height:auto; display:block; margin:auto;"/>
      <div class="content" style="text-align:justify; width:720px; margin:auto;">
      <p>Qualitative evaluations of BiPO highlight its ability to produce fluid, context-rich human motions that capture nuanced details of the textual description. From dynamic activities like “a person hops in place and then starts to sway” to more subtle sequences like “a person carefully leans forward to pick up an object,” BiPO’s outputs stand out as natural, lifelike, and semantically aligned. Compared to prior methods, BiPO demonstrates clearer transitions, balanced posture control, and fine-grained articulation in limbs. These tests illustrate how the model’s architecture and training strategy combine to yield motions that not only look realistic but also faithfully reflect the intended textual narrative.</p>
      </div>
      </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container" style="text-align:center;">
    <h2 class="title is-3">Motion Editing</h2>
    <img src="static/figures/Figure6.PNG" alt="BiPO Architecture Diagram" style="width:720px; height:auto; display:block; margin:auto;"/>
    <div class="content" style="text-align:justify; width:720px; margin:auto;">
    <p>Beyond straightforward text-to-motion generation, BiPO excels in motion editing tasks, where only partial information—such as a starting pose or a midpoint sequence—is provided. Through its bidirectional inference process and robust part-based representation, BiPO can seamlessly fill in missing segments, extend a partially completed motion, or adjust the trajectory to accommodate new textual constraints. Whether predicting the next steps of a dancer after a given pose or completing the beginning and end of a walking sequence, BiPO maintains consistency, style, and semantic fidelity to the user’s directions. This adaptability opens new possibilities for iterative refinement and user-guided editing of 3D human motion data.</p>
    </div>
    </div>
</section>

<section class="section hero is-light">
  <div class="container" style="text-align:center;">
    <h2 class="title is-3">BibTeX</h2>
    <div class="content" style="width:720px; margin:auto; text-align:left;">
<pre><code>
@article{hong2024bipo,
  title={BiPO: Bidirectional Partial Occlusion Network for Text-to-Motion Synthesis},
  author={Hong, Seong-Eun and Lim, Soobin and Hwang, Juyeong and Chang, Minwook and Kang, Hyeongyeop},
  journal={arXiv preprint arXiv:2412.00112},
  year={2024}
}
</code></pre>
    </div>
  </div>
</section>

<footer class="footer" style="background-color: #f8f9fa; padding: 20px 0; width: 100%;">
  <div style="width: 100%; text-align: left; padding: 0 20px;">
    <p>
      This website is licensed under a <a rel="license"
      href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
      Commons Attribution-ShareAlike 4.0 International License</a>.
    </p>
    <p>
      Website source code based on the <a href="https://nerfies.github.io/">Nerfies</a> project page. If you want to reuse their <a
      href="https://github.com/nerfies/nerfies.github.io">source code</a>, please credit them appropriately.
    </p>
  </div>
</footer>

<script type="text/javascript">
  var sc_project=12351448; 
  var sc_invisible=1; 
  var sc_security="c676de4f"; 
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics"
  href="https://statcounter.com/" target="_blank"><img
  class="statcounter"
  src="https://c.statcounter.com/12351448/0/c676de4f/1/"
  alt="Web Analytics"></a></div></noscript>
<!-- End of Statcounter Code -->

</body>
</html>
